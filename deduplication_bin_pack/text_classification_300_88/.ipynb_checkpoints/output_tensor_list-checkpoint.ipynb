{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88474269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#input = np.load('detector_output.npy', allow_pickle=True).item()\n",
    "#input = np.load('detector_output_diff_size_unshared_located_random.npy', allow_pickle=True).item()\n",
    "#input = np.load('detector_output_same_size_unshared_located_random.npy', allow_pickle=True).item()\n",
    "#input = np.load('detector_output_same_size_unshared_located_at_last.npy', allow_pickle=True).item()\n",
    "\n",
    "list_of_tensors = list()\n",
    "\n",
    "input_1 = np.load('civil_trainable.npy', allow_pickle=True).item()\n",
    "block_size_1 = input_1.get('block_size')\n",
    "#unique_blocks_1 = len(input_1.get('list_blocks'))\n",
    "tensor_shapes_1 = input_1.get('blocked_tensor_dimension')\n",
    "tensor_mapping_1 = input_1.get('tensor_mapping')\n",
    "num_tensors_1 = len(tensor_shapes_1)\n",
    "\n",
    "for i in range (num_tensors_1):\n",
    "    tensor_shapes_1[i] = input_1.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors_1):\n",
    "    first, snd = tensor_shapes_1[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping_1[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "\n",
    "input_2 = np.load('imdb_nontrainable.npy', allow_pickle=True).item()\n",
    "block_size_2 = input_2.get('block_size')\n",
    "#unique_blocks_2 = len(input_2.get('list_blocks'))\n",
    "tensor_shapes_2 = input_2.get('blocked_tensor_dimension')\n",
    "tensor_mapping_2 = input_2.get('tensor_mapping')\n",
    "num_tensors_2 = len(tensor_shapes_2)\n",
    "\n",
    "for i in range (num_tensors_2):\n",
    "    tensor_shapes_2[i] = input_2.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors_2):\n",
    "    first, snd = tensor_shapes_2[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping_2[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "\n",
    "input_3 = np.load('imdb_trainable.npy', allow_pickle=True).item()\n",
    "block_size_3 = input_3.get('block_size')\n",
    "#unique_blocks_3 = len(input_3.get('list_blocks'))\n",
    "tensor_shapes_3 = input_3.get('blocked_tensor_dimension')\n",
    "tensor_mapping_3 = input_3.get('tensor_mapping')\n",
    "num_tensors_3 = len(tensor_shapes_3)\n",
    "\n",
    "for i in range (num_tensors_3):\n",
    "    tensor_shapes_3[i] = input_3.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors_3):\n",
    "    first, snd = tensor_shapes_3[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping_3[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "\n",
    "input_4 = np.load('yelp_nontrainable.npy', allow_pickle=True).item()\n",
    "block_size_4 = input_4.get('block_size')\n",
    "#unique_blocks_4 = len(input_4.get('list_blocks'))\n",
    "tensor_shapes_4 = input_4.get('blocked_tensor_dimension')\n",
    "tensor_mapping_4 = input_4.get('tensor_mapping')\n",
    "num_tensors_4 = len(tensor_shapes_4)\n",
    "\n",
    "for i in range (num_tensors_4):\n",
    "    tensor_shapes_4[i] = input_4.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors_4):\n",
    "    first, snd = tensor_shapes_4[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping_4[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "\n",
    "input_5 = np.load('yelp_trainable.npy', allow_pickle=True).item()\n",
    "block_size_5 = input_5.get('block_size')\n",
    "tensor_shapes_5 = input_5.get('blocked_tensor_dimension')\n",
    "tensor_mapping_5 = input_5.get('tensor_mapping')\n",
    "num_tensors_5 = len(tensor_shapes_5)\n",
    "\n",
    "for i in range (num_tensors_5):\n",
    "    tensor_shapes_5[i] = input_5.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors_5):\n",
    "    first, snd = tensor_shapes_5[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping_5[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "    \n",
    "num_tensors = num_tensors_1 + num_tensors_2 + num_tensors_3 + num_tensors_4 + num_tensors_5\n",
    "\n",
    "#print(list_of_tensors)\n",
    "#print(num_tensors)\n",
    "output = dict()\n",
    "output['list_of_tensors'] = list_of_tensors\n",
    "np.save('tensor_list.npy', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9140d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_dp(T):\n",
    "    share_by_all = set()\n",
    "    share_by_own = list()\n",
    "    for i in range (len(T)):\n",
    "        if(len(T[i]) == 1):\n",
    "            share_by_own.append(T[i])\n",
    "            continue\n",
    "        else:\n",
    "            long_tensor = T[i]\n",
    "            new_set = set()\n",
    "            for j in range (len(long_tensor)):\n",
    "                current_list = list()\n",
    "                if (long_tensor[j] in T[0] and long_tensor[j] in T[5] and long_tensor[j] in T[10] and long_tensor[j] in T[15] and long_tensor[j] in T[20]):\n",
    "                    new_set.add(long_tensor[j])\n",
    "                elif (long_tensor[j] in T[i] and long_tensor[j] not in T[int(abs(5-(i/5+1))*5)] and long_tensor[j] not in T[int(abs(5-(i/5+2))*5)] and long_tensor[j] not in T[int(abs(5-(i/5+3))*5)] and long_tensor[j] not in T[int(abs(5-(i/5+4))*5)]):\n",
    "                    current_set = set(current_list)\n",
    "                    current_set.add(long_tensor[j])\n",
    "                    current_list = list(current_set)\n",
    "            share_by_own.append(current_list)\n",
    "            share_by_all = share_by_all | new_set\n",
    "            T[i] = list(set(T[i]) - new_set)\n",
    "    for i in range(25):\n",
    "        print(share_by_own[i])\n",
    "    print(len(share_by_all))\n",
    "    print(len(T[0]))\n",
    "    return T\n",
    "    \n",
    "list_of_tensors = pre_dp(list_of_tensors)\n",
    "new_list_of_tensors = list()\n",
    "for i in range(len(list_of_tensors)):\n",
    "    if (len(list_of_tensors[i]) != 1):\n",
    "        new_list_of_tensors.append(list_of_tensors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4157c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output = np.load('tensor_list.npy', allow_pickle=True).item()\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebe36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['list_of_tensors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b0e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
