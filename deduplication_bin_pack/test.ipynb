{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a091fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input = np.load('detector_output.npy', allow_pickle=True).item()\n",
    "block_size = input.get('block_size')\n",
    "unique_blocks = len(input.get('list_blocks'))\n",
    "tensor_shapes = input.get('blocked_tensor_dimension')\n",
    "tensor_mapping = input.get('tensor_mapping')\n",
    "num_tensors = len(tensor_shapes)\n",
    "\n",
    "list_of_tensors = list()\n",
    "for i in range (num_tensors):\n",
    "    tensor_shapes[i] = input.get('blocked_tensor_dimension')[i]\n",
    "for t in range(num_tensors):\n",
    "    first, snd = tensor_shapes[t]\n",
    "    l = list()\n",
    "    for i in range(first):\n",
    "        for j in range(snd):\n",
    "            l.append(tensor_mapping[t].get((i,j)))\n",
    "    list_of_tensors.append(l)\n",
    "#print(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fcac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.arraysetops import unique\n",
    "from bin_pack import *\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "\"\"\"\n",
    "10 tensors\n",
    "each tensor has - 10^4 x 10^4 ~100MB - 10k blocks in total, 1k, 2k, 4k, 8k ... unique blocks\n",
    "ratio of unique blocks in each tensor\n",
    "1. evenly distribute\n",
    "2. ~80% shared, 20% unshared for every tensor\n",
    "3. Probablility distribution - random\n",
    "Each unique block has 10% share in each tensor\n",
    "\n",
    "4. For each unique block, sample a tensor, place it into that tensor. Repeat with every unique block till all tensors are filled \n",
    "5. For each tensor, sample a unique block\n",
    "\n",
    "Report ideal deduplication factor - max number of blocks \n",
    "\"\"\"\n",
    "\n",
    "# 1. Amount of space saved\n",
    "# 2. How much time for dp vs greedy\n",
    "# 3. Naive packing comparision - time and space i.e data loading time for non-shared\n",
    "\n",
    "\n",
    "class Tensor(object):\n",
    "    def __init__(self, blocks=None, shape=None, block_shape=None, name=None):\n",
    "        self.tensor_blocks = blocks or []\n",
    "        self.shape = shape\n",
    "        self.block_shape = block_shape\n",
    "        self.name = name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_blocks)\n",
    "\n",
    "    def num_blocks(self):\n",
    "        if not self.shape:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.multiply(*self.shape)\n",
    "\n",
    "    def __eq__(self, o):\n",
    "        return self.name == o.name\n",
    "\n",
    "    def __ne__(self, o):\n",
    "        return self.name != o.name\n",
    "\n",
    "    def __hash__(self):\n",
    "        return int(hashlib.md5(self.name.encode('utf-8')).hexdigest(), 16)\n",
    "\n",
    "    def get_block(self):\n",
    "        return (self.name,)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor_blocks[idx]\n",
    "\n",
    "    def __setitem__(self, idx, item):\n",
    "        self.tensor_blocks[idx] = item\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.pos = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.pos >= len(self.tensor_blocks):\n",
    "            raise StopIteration\n",
    "\n",
    "        ret = self.tensor_blocks[self.pos]\n",
    "        self.pos += 1\n",
    "        return ret\n",
    "\n",
    "\n",
    "# def equal_distribution(tensors, unique_blocks, use_all=True):\n",
    "#     unique_per_tensor = unique_blocks // len(tensors)\n",
    "#     exclude = []\n",
    "#     left = 0\n",
    "#     for t in tensors:\n",
    "#         if t.num_blocks() < unique_per_tensor:\n",
    "#             t.tensor_blocks = t.num_blocks()\n",
    "#             left += unique_per_tensor - t.num_blocks()\n",
    "#             exclude.append(t)\n",
    "#         else:\n",
    "#             t.tensor_blocks = unique_per_tensor\n",
    "\n",
    "#     \"\"\"\n",
    "#     If tensor sizes are randomly generated, its possible that unique_per_tensor > the size of the tensor\n",
    "#     Fill up the small tensors and redistribute the remaining unique blocks among the other remaining tensors\n",
    "#     \"\"\"\n",
    "#     if left > 0 and exclude and use_all:\n",
    "#         equal_distribution([t for t in tensors if t not in exclude], left)\n",
    "\n",
    "\n",
    "# def percentage_distribution(tensors, percentage_unique_per_tensor):\n",
    "#     # We may not use all the unique_blocks depending on the shapes of the arrays\n",
    "#     for t in tensors:\n",
    "#         t.tensor_blocks = percentage_unique_per_tensor * t.num_blocks()\n",
    "\n",
    "\n",
    "def block_distribution(tensors, unique_blocks):\n",
    "    T = [t for t in tensors]\n",
    "    while T:\n",
    "        for b in unique_blocks:\n",
    "            t = np.random.choice(T, 1)[0]\n",
    "            t.tensor_blocks.append(b)\n",
    "            if len(t.tensor_blocks) == t.num_blocks():\n",
    "                T.remove(t)\n",
    "\n",
    "\n",
    "def tensor_distribution(tensors, unique_blocks):\n",
    "    T = [t for t in tensors]\n",
    "    while T:\n",
    "        for t in tensors:\n",
    "            b = np.random.choice(unique_blocks, 1)[0]\n",
    "            t.tensor_blocks.append(b)\n",
    "            if len(t.tensor_blocks) == t.num_blocks():\n",
    "                T.remove(t)\n",
    "\n",
    "\n",
    "distribution_mode = {\n",
    "    # \"equal\": equal_distribution,\n",
    "    # \"percentage\": percentage_distribution,\n",
    "    \"block\": block_distribution,\n",
    "    \"tensor\": tensor_distribution\n",
    "}\n",
    "\n",
    "\n",
    "def generate_random_tensors(\n",
    "    num_tensors,\n",
    "    block_shape,\n",
    "    num_unique_blocks,\n",
    "    distribution_ops,\n",
    "    max_tensor_blocks=None,\n",
    "    tensor_shape=None\n",
    "):\n",
    "    assert(num_tensors > 0)\n",
    "    unique_blocks = [uuid.uuid1().hex for _ in range(num_unique_blocks)]\n",
    "\n",
    "    tensor_shapes = []\n",
    "\n",
    "    if max_tensor_blocks and not tensor_shape and isinstance(max_tensor_blocks, tuple):\n",
    "        rng = np.random.default_rng(12345)\n",
    "        tensor_shapes = [\n",
    "            (rng.integers(low=1, high=max_tensor_blocks[0], size=1), rng.integers(low=1, high=max_tensor_blocks[1], size=1),)\n",
    "            for _ in range(num_tensors)\n",
    "        ]\n",
    "    elif tensor_shape and not max_tensor_blocks:\n",
    "        if isinstance(tensor_shape, tuple):\n",
    "            tensor_shapes = [tensor_shape for _ in range(num_tensors)]\n",
    "        elif isinstance(tensor_shape, list) and len(tensor_shape) == num_tensors and isinstance(tensor_shape[0], tuple):\n",
    "            tensor_shapes = tensor_shape\n",
    "        else:\n",
    "            raise Exception(\"tensor_shape must be a tuple or a list of tuples\")\n",
    "    else:\n",
    "        raise Exception(\"Either need tensor_shape for user-defined sized tensors or max_tensor_blocks tuple to generate random shaped tensors\")\n",
    "\n",
    "    total_blocks = np.prod([a * b for a,b in tensor_shapes])\n",
    "\n",
    "    tensors = [Tensor(name=f\"t{i}\", shape=tensor_shapes[i], block_shape=block_shape) for i in range(num_tensors)]\n",
    "\n",
    "    distribution_mode[distribution_ops['mode']](tensors, unique_blocks, **distribution_ops.get('kwargs', {}))\n",
    "\n",
    "    return tensors, total_blocks\n",
    "\n",
    "blocks_in_page = 10 # page can have 10 blocks\n",
    "P = set()\n",
    "P = bin_pack_greedy(list_of_tensors, blocks_in_page)\n",
    "L = list(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a8c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_page_mapping\n",
      "\n",
      "{0: 166, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 1, 11: 1, 12: 1, 13: 155, 14: 166, 15: 1, 16: 1, 17: 1, 18: 155, 19: 155, 20: 166, 21: 2, 22: 2, 23: 155, 24: 2, 25: 2, 26: 2, 27: 2, 28: 2, 29: 2, 30: 3, 31: 3, 32: 3, 33: 3, 34: 3, 35: 3, 36: 3, 37: 3, 38: 3, 39: 3, 40: 4, 41: 4, 42: 4, 43: 166, 44: 4, 45: 4, 46: 4, 47: 4, 48: 4, 49: 4, 50: 5, 51: 5, 52: 166, 53: 5, 54: 5, 55: 5, 56: 5, 57: 5, 58: 166, 59: 5, 60: 6, 61: 6, 62: 166, 63: 155, 64: 6, 65: 6, 66: 6, 67: 6, 68: 6, 69: 6, 70: 7, 71: 7, 72: 7, 73: 7, 74: 7, 75: 7, 76: 7, 77: 166, 78: 150, 79: 7, 80: 8, 81: 151, 82: 8, 83: 8, 84: 8, 85: 8, 86: 8, 87: 8, 88: 8, 89: 8, 90: 166, 91: 9, 92: 9, 93: 9, 94: 9, 95: 9, 96: 9, 97: 9, 98: 9, 99: 9, 100: 151, 101: 10, 102: 10, 103: 10, 104: 10, 105: 10, 106: 10, 107: 10, 108: 10, 109: 155, 110: 11, 111: 11, 112: 11, 113: 11, 114: 11, 115: 151, 116: 11, 117: 11, 118: 11, 119: 11, 120: 12, 121: 12, 122: 12, 123: 12, 124: 12, 125: 12, 126: 12, 127: 12, 128: 12, 129: 12, 130: 13, 131: 13, 132: 13, 133: 13, 134: 155, 135: 13, 136: 13, 137: 13, 138: 13, 139: 13, 140: 14, 141: 14, 142: 167, 143: 14, 144: 167, 145: 14, 146: 14, 147: 14, 148: 14, 149: 14, 150: 167, 151: 15, 152: 15, 153: 15, 154: 15, 155: 15, 156: 15, 157: 15, 158: 15, 159: 15, 160: 16, 161: 156, 162: 16, 163: 151, 164: 16, 165: 16, 166: 16, 167: 16, 168: 167, 169: 167, 170: 17, 171: 17, 172: 17, 173: 17, 174: 156, 175: 167, 176: 17, 177: 17, 178: 17, 179: 17, 180: 18, 181: 167, 182: 18, 183: 18, 184: 18, 185: 18, 186: 18, 187: 18, 188: 18, 189: 18, 190: 19, 191: 19, 192: 19, 193: 19, 194: 19, 195: 19, 196: 19, 197: 19, 198: 19, 199: 156, 200: 167, 201: 156, 202: 156, 203: 150, 204: 20, 205: 20, 206: 20, 207: 20, 208: 151, 209: 20, 210: 156, 211: 21, 212: 21, 213: 21, 214: 21, 215: 21, 216: 21, 217: 21, 218: 21, 219: 21, 220: 167, 221: 22, 222: 22, 223: 167, 224: 22, 225: 22, 226: 22, 227: 22, 228: 22, 229: 168, 230: 23, 231: 23, 232: 23, 233: 23, 234: 23, 235: 168, 236: 23, 237: 150, 238: 168, 239: 23, 240: 24, 241: 24, 242: 24, 243: 24, 244: 24, 245: 24, 246: 24, 247: 168, 248: 24, 249: 24, 250: 168, 251: 156, 252: 25, 253: 25, 254: 25, 255: 25, 256: 151, 257: 156, 258: 25, 259: 25, 260: 26, 261: 26, 262: 26, 263: 26, 264: 26, 265: 26, 266: 26, 267: 152, 268: 26, 269: 26, 270: 27, 271: 27, 272: 156, 273: 27, 274: 27, 275: 27, 276: 156, 277: 27, 278: 27, 279: 27, 280: 28, 281: 168, 282: 28, 283: 28, 284: 28, 285: 28, 286: 28, 287: 28, 288: 28, 289: 28, 290: 29, 291: 29, 292: 29, 293: 168, 294: 29, 295: 29, 296: 168, 297: 29, 298: 29, 299: 29, 300: 30, 301: 30, 302: 30, 303: 30, 304: 30, 305: 30, 306: 30, 307: 30, 308: 30, 309: 30, 310: 168, 311: 31, 312: 31, 313: 168, 314: 31, 315: 31, 316: 31, 317: 31, 318: 31, 319: 31, 320: 32, 321: 32, 322: 32, 323: 32, 324: 157, 325: 32, 326: 157, 327: 32, 328: 169, 329: 32, 330: 33, 331: 33, 332: 33, 333: 33, 334: 169, 335: 169, 336: 33, 337: 33, 338: 33, 339: 152, 340: 157, 341: 34, 342: 34, 343: 34, 344: 34, 345: 34, 346: 34, 347: 157, 348: 34, 349: 157, 350: 35, 351: 150, 352: 169, 353: 169, 354: 35, 355: 35, 356: 35, 357: 35, 358: 35, 359: 169, 360: 36, 361: 36, 362: 169, 363: 36, 364: 36, 365: 36, 366: 36, 367: 36, 368: 36, 369: 36, 370: 37, 371: 37, 372: 37, 373: 37, 374: 37, 375: 37, 376: 152, 377: 37, 378: 37, 379: 37, 380: 38, 381: 38, 382: 38, 383: 38, 384: 38, 385: 38, 386: 38, 387: 38, 388: 169, 389: 38, 390: 39, 391: 39, 392: 39, 393: 39, 394: 39, 395: 39, 396: 39, 397: 39, 398: 39, 399: 39, 400: 40, 401: 152, 402: 40, 403: 40, 404: 40, 405: 40, 406: 40, 407: 169, 408: 169, 409: 40, 410: 170, 411: 41, 412: 157, 413: 157, 414: 41, 415: 41, 416: 41, 417: 157, 418: 41, 419: 41, 420: 42, 421: 157, 422: 42, 423: 42, 424: 42, 425: 42, 426: 42, 427: 42, 428: 42, 429: 152, 430: 157, 431: 43, 432: 170, 433: 43, 434: 43, 435: 43, 436: 43, 437: 43, 438: 43, 439: 43, 440: 44, 441: 44, 442: 44, 443: 152, 444: 44, 445: 44, 446: 44, 447: 44, 448: 44, 449: 44, 450: 45, 451: 45, 452: 152, 453: 170, 454: 45, 455: 45, 456: 45, 457: 45, 458: 45, 459: 45, 460: 170, 461: 46, 462: 46, 463: 46, 464: 46, 465: 46, 466: 46, 467: 46, 468: 170, 469: 46, 470: 47, 471: 47, 472: 47, 473: 47, 474: 47, 475: 150, 476: 47, 477: 47, 478: 47, 479: 47, 480: 48, 481: 48, 482: 48, 483: 48, 484: 48, 485: 48, 486: 48, 487: 48, 488: 170, 489: 48, 490: 49, 491: 49, 492: 49, 493: 170, 494: 49, 495: 49, 496: 49, 497: 49, 498: 49, 499: 49, 500: 50, 501: 158, 502: 50, 503: 50, 504: 50, 505: 50, 506: 50, 507: 50, 508: 50, 509: 152, 510: 51, 511: 51, 512: 170, 513: 170, 514: 51, 515: 170, 516: 51, 517: 51, 518: 51, 519: 51, 520: 52, 521: 171, 522: 52, 523: 171, 524: 52, 525: 52, 526: 52, 527: 52, 528: 52, 529: 52, 530: 53, 531: 53, 532: 53, 533: 53, 534: 53, 535: 158, 536: 53, 537: 171, 538: 53, 539: 53, 540: 54, 541: 171, 542: 54, 543: 54, 544: 54, 545: 54, 546: 171, 547: 54, 548: 54, 549: 54, 550: 55, 551: 55, 552: 55, 553: 55, 554: 171, 555: 55, 556: 171, 557: 55, 558: 55, 559: 55, 560: 56, 561: 56, 562: 56, 563: 171, 564: 56, 565: 56, 566: 56, 567: 56, 568: 56, 569: 56, 570: 158, 571: 57, 572: 57, 573: 171, 574: 158, 575: 57, 576: 158, 577: 57, 578: 57, 579: 57, 580: 171, 581: 58, 582: 58, 583: 58, 584: 58, 585: 58, 586: 58, 587: 58, 588: 58, 589: 58, 590: 59, 591: 172, 592: 59, 593: 59, 594: 59, 595: 59, 596: 59, 597: 59, 598: 59, 599: 158, 600: 60, 601: 60, 602: 60, 603: 60, 604: 60, 605: 172, 606: 60, 607: 60, 608: 172, 609: 172, 610: 61, 611: 172, 612: 61, 613: 61, 614: 61, 615: 61, 616: 61, 617: 61, 618: 61, 619: 61, 620: 62, 621: 158, 622: 62, 623: 62, 624: 158, 625: 172, 626: 62, 627: 62, 628: 158, 629: 158, 630: 63, 631: 63, 632: 63, 633: 63, 634: 172, 635: 172, 636: 63, 637: 63, 638: 63, 639: 63, 640: 64, 641: 64, 642: 172, 643: 64, 644: 64, 645: 64, 646: 64, 647: 64, 648: 64, 649: 64, 650: 65, 651: 65, 652: 172, 653: 65, 654: 65, 655: 65, 656: 65, 657: 65, 658: 65, 659: 65, 660: 66, 661: 66, 662: 66, 663: 173, 664: 66, 665: 66, 666: 66, 667: 66, 668: 66, 669: 66, 670: 173, 671: 159, 672: 152, 673: 173, 674: 67, 675: 173, 676: 150, 677: 67, 678: 67, 679: 173, 680: 68, 681: 68, 682: 68, 683: 68, 684: 68, 685: 68, 686: 68, 687: 173, 688: 68, 689: 68, 690: 69, 691: 69, 692: 69, 693: 69, 694: 69, 695: 69, 696: 159, 697: 159, 698: 69, 699: 69, 700: 70, 701: 70, 702: 70, 703: 70, 704: 70, 705: 70, 706: 70, 707: 70, 708: 70, 709: 70, 710: 71, 711: 71, 712: 159, 713: 71, 714: 71, 715: 173, 716: 71, 717: 173, 718: 71, 719: 71, 720: 72, 721: 72, 722: 72, 723: 72, 724: 72, 725: 72, 726: 159, 727: 72, 728: 72, 729: 72, 730: 73, 731: 73, 732: 73, 733: 159, 734: 73, 735: 173, 736: 73, 737: 73, 738: 73, 739: 73, 740: 74, 741: 74, 742: 74, 743: 173, 744: 74, 745: 74, 746: 74, 747: 74, 748: 74, 749: 74, 750: 152, 751: 174, 752: 150, 753: 75, 754: 174, 755: 75, 756: 75, 757: 75, 758: 75, 759: 75, 760: 76, 761: 76, 762: 76, 763: 76, 764: 76, 765: 76, 766: 76, 767: 76, 768: 76, 769: 76, 770: 77, 771: 77, 772: 77, 773: 77, 774: 77, 775: 77, 776: 174, 777: 77, 778: 77, 779: 77, 780: 174, 781: 153, 782: 78, 783: 159, 784: 78, 785: 78, 786: 78, 787: 78, 788: 78, 789: 78, 790: 79, 791: 174, 792: 79, 793: 79, 794: 79, 795: 79, 796: 79, 797: 79, 798: 79, 799: 79, 800: 80, 801: 80, 802: 80, 803: 80, 804: 80, 805: 80, 806: 80, 807: 80, 808: 174, 809: 80, 810: 81, 811: 81, 812: 81, 813: 81, 814: 81, 815: 81, 816: 81, 817: 174, 818: 81, 819: 81, 820: 174, 821: 174, 822: 82, 823: 82, 824: 82, 825: 82, 826: 174, 827: 159, 828: 82, 829: 82, 830: 83, 831: 83, 832: 83, 833: 83, 834: 83, 835: 83, 836: 83, 837: 83, 838: 83, 839: 175, 840: 84, 841: 84, 842: 159, 843: 84, 844: 175, 845: 84, 846: 84, 847: 84, 848: 84, 849: 84, 850: 85, 851: 85, 852: 85, 853: 159, 854: 85, 855: 160, 856: 85, 857: 85, 858: 175, 859: 85, 860: 86, 861: 86, 862: 86, 863: 86, 864: 86, 865: 86, 866: 86, 867: 160, 868: 86, 869: 175, 870: 160, 871: 160, 872: 87, 873: 150, 874: 153, 875: 87, 876: 87, 877: 87, 878: 175, 879: 160, 880: 88, 881: 175, 882: 88, 883: 88, 884: 160, 885: 88, 886: 88, 887: 88, 888: 88, 889: 88, 890: 89, 891: 89, 892: 175, 893: 89, 894: 89, 895: 89, 896: 89, 897: 153, 898: 89, 899: 89, 900: 90, 901: 175, 902: 90, 903: 153, 904: 90, 905: 90, 906: 90, 907: 90, 908: 90, 909: 175, 910: 91, 911: 91, 912: 91, 913: 91, 914: 91, 915: 91, 916: 91, 917: 91, 918: 91, 919: 91, 920: 92, 921: 92, 922: 92, 923: 92, 924: 153, 925: 92, 926: 92, 927: 92, 928: 175, 929: 92, 930: 93, 931: 93, 932: 93, 933: 93, 934: 93, 935: 93, 936: 93, 937: 93, 938: 93, 939: 93, 940: 94, 941: 176, 942: 94, 943: 94, 944: 94, 945: 94, 946: 94, 947: 94, 948: 94, 949: 94, 950: 95, 951: 95, 952: 95, 953: 95, 954: 95, 955: 95, 956: 95, 957: 160, 958: 95, 959: 95, 960: 96, 961: 96, 962: 96, 963: 96, 964: 96, 965: 96, 966: 96, 967: 96, 968: 160, 969: 96, 970: 97, 971: 97, 972: 97, 973: 97, 974: 97, 975: 97, 976: 97, 977: 176, 978: 97, 979: 97, 980: 98, 981: 176, 982: 176, 983: 98, 984: 98, 985: 98, 986: 98, 987: 98, 988: 98, 989: 98, 990: 160, 991: 160, 992: 176, 993: 99, 994: 161, 995: 176, 996: 99, 997: 99, 998: 161, 999: 176, 1000: 100, 1001: 100, 1002: 100, 1003: 100, 1004: 100, 1005: 100, 1006: 100, 1007: 176, 1008: 176, 1009: 176, 1010: 101, 1011: 101, 1012: 101, 1013: 101, 1014: 101, 1015: 177, 1016: 101, 1017: 101, 1018: 101, 1019: 101, 1020: 177, 1021: 161, 1022: 102, 1023: 102, 1024: 102, 1025: 102, 1026: 177, 1027: 153, 1028: 102, 1029: 102, 1030: 103, 1031: 103, 1032: 103, 1033: 103, 1034: 103, 1035: 103, 1036: 103, 1037: 103, 1038: 103, 1039: 103, 1040: 177, 1041: 104, 1042: 104, 1043: 177, 1044: 104, 1045: 104, 1046: 177, 1047: 104, 1048: 104, 1049: 104, 1050: 105, 1051: 105, 1052: 105, 1053: 177, 1054: 105, 1055: 105, 1056: 105, 1057: 105, 1058: 161, 1059: 177, 1060: 106, 1061: 106, 1062: 106, 1063: 106, 1064: 106, 1065: 106, 1066: 177, 1067: 106, 1068: 106, 1069: 106, 1070: 107, 1071: 107, 1072: 107, 1073: 107, 1074: 107, 1075: 177, 1076: 107, 1077: 107, 1078: 107, 1079: 107, 1080: 108, 1081: 161, 1082: 108, 1083: 108, 1084: 178, 1085: 178, 1086: 108, 1087: 178, 1088: 178, 1089: 108, 1090: 109, 1091: 109, 1092: 109, 1093: 161, 1094: 109, 1095: 178, 1096: 153, 1097: 161, 1098: 109, 1099: 161, 1100: 110, 1101: 178, 1102: 110, 1103: 178, 1104: 110, 1105: 110, 1106: 110, 1107: 178, 1108: 110, 1109: 110, 1110: 161, 1111: 111, 1112: 111, 1113: 111, 1114: 111, 1115: 111, 1116: 111, 1117: 161, 1118: 111, 1119: 111, 1120: 112, 1121: 112, 1122: 112, 1123: 112, 1124: 112, 1125: 112, 1126: 112, 1127: 112, 1128: 112, 1129: 112, 1130: 113, 1131: 113, 1132: 113, 1133: 113, 1134: 113, 1135: 113, 1136: 113, 1137: 153, 1138: 178, 1139: 162, 1140: 114, 1141: 114, 1142: 114, 1143: 114, 1144: 114, 1145: 114, 1146: 178, 1147: 114, 1148: 114, 1149: 162, 1150: 115, 1151: 115, 1152: 115, 1153: 115, 1154: 153, 1155: 115, 1156: 115, 1157: 115, 1158: 115, 1159: 179, 1160: 116, 1161: 116, 1162: 116, 1163: 116, 1164: 162, 1165: 116, 1166: 116, 1167: 116, 1168: 116, 1169: 116, 1170: 117, 1171: 117, 1172: 117, 1173: 117, 1174: 117, 1175: 117, 1176: 117, 1177: 117, 1178: 117, 1179: 179, 1180: 118, 1181: 118, 1182: 118, 1183: 118, 1184: 118, 1185: 162, 1186: 118, 1187: 118, 1188: 118, 1189: 118, 1190: 119, 1191: 179, 1192: 119, 1193: 119, 1194: 119, 1195: 119, 1196: 119, 1197: 119, 1198: 162, 1199: 119, 1200: 179, 1201: 120, 1202: 120, 1203: 120, 1204: 120, 1205: 162, 1206: 120, 1207: 179, 1208: 120, 1209: 153, 1210: 121, 1211: 179, 1212: 121, 1213: 179, 1214: 121, 1215: 121, 1216: 121, 1217: 121, 1218: 121, 1219: 121, 1220: 179, 1221: 122, 1222: 179, 1223: 122, 1224: 122, 1225: 122, 1226: 162, 1227: 122, 1228: 179, 1229: 122, 1230: 123, 1231: 123, 1232: 123, 1233: 123, 1234: 150, 1235: 123, 1236: 154, 1237: 123, 1238: 123, 1239: 123, 1240: 124, 1241: 124, 1242: 124, 1243: 124, 1244: 124, 1245: 124, 1246: 124, 1247: 124, 1248: 150, 1249: 124, 1250: 125, 1251: 125, 1252: 125, 1253: 125, 1254: 125, 1255: 162, 1256: 125, 1257: 125, 1258: 125, 1259: 125, 1260: 180, 1261: 126, 1262: 180, 1263: 126, 1264: 126, 1265: 126, 1266: 126, 1267: 126, 1268: 180, 1269: 126, 1270: 127, 1271: 127, 1272: 127, 1273: 127, 1274: 127, 1275: 127, 1276: 127, 1277: 127, 1278: 180, 1279: 162, 1280: 128, 1281: 128, 1282: 128, 1283: 128, 1284: 128, 1285: 128, 1286: 128, 1287: 128, 1288: 128, 1289: 128, 1290: 129, 1291: 129, 1292: 180, 1293: 162, 1294: 129, 1295: 129, 1296: 129, 1297: 129, 1298: 129, 1299: 129, 1300: 130, 1301: 130, 1302: 130, 1303: 130, 1304: 130, 1305: 130, 1306: 130, 1307: 130, 1308: 130, 1309: 130, 1310: 180, 1311: 131, 1312: 131, 1313: 131, 1314: 131, 1315: 131, 1316: 131, 1317: 131, 1318: 131, 1319: 131, 1320: 132, 1321: 132, 1322: 132, 1323: 180, 1324: 132, 1325: 132, 1326: 132, 1327: 132, 1328: 163, 1329: 132, 1330: 133, 1331: 133, 1332: 133, 1333: 133, 1334: 133, 1335: 133, 1336: 133, 1337: 133, 1338: 133, 1339: 133, 1340: 154, 1341: 134, 1342: 163, 1343: 134, 1344: 154, 1345: 134, 1346: 134, 1347: 163, 1348: 134, 1349: 134, 1350: 163, 1351: 135, 1352: 180, 1353: 135, 1354: 135, 1355: 180, 1356: 135, 1357: 180, 1358: 181, 1359: 135, 1360: 136, 1361: 136, 1362: 136, 1363: 136, 1364: 163, 1365: 136, 1366: 136, 1367: 136, 1368: 136, 1369: 136, 1370: 137, 1371: 137, 1372: 137, 1373: 137, 1374: 163, 1375: 137, 1376: 137, 1377: 137, 1378: 137, 1379: 137, 1380: 138, 1381: 138, 1382: 163, 1383: 138, 1384: 138, 1385: 138, 1386: 138, 1387: 138, 1388: 138, 1389: 138, 1390: 139, 1391: 139, 1392: 139, 1393: 139, 1394: 139, 1395: 139, 1396: 139, 1397: 139, 1398: 139, 1399: 139, 1400: 140, 1401: 140, 1402: 140, 1403: 140, 1404: 140, 1405: 140, 1406: 140, 1407: 140, 1408: 181, 1409: 140, 1410: 141, 1411: 141, 1412: 141, 1413: 141, 1414: 141, 1415: 141, 1416: 181, 1417: 141, 1418: 141, 1419: 141, 1420: 142, 1421: 142, 1422: 142, 1423: 142, 1424: 181, 1425: 142, 1426: 142, 1427: 142, 1428: 181, 1429: 142, 1430: 163, 1431: 143, 1432: 143, 1433: 143, 1434: 143, 1435: 143, 1436: 143, 1437: 143, 1438: 143, 1439: 143, 1440: 144, 1441: 144, 1442: 144, 1443: 144, 1444: 144, 1445: 144, 1446: 144, 1447: 163, 1448: 144, 1449: 154, 1450: 145, 1451: 145, 1452: 145, 1453: 145, 1454: 163, 1455: 164, 1456: 145, 1457: 181, 1458: 145, 1459: 145, 1460: 146, 1461: 146, 1462: 146, 1463: 146, 1464: 146, 1465: 146, 1466: 146, 1467: 146, 1468: 146, 1469: 146, 1470: 147, 1471: 147, 1472: 147, 1473: 147, 1474: 147, 1475: 147, 1476: 147, 1477: 147, 1478: 147, 1479: 147, 1480: 148, 1481: 148, 1482: 148, 1483: 164, 1484: 181, 1485: 148, 1486: 148, 1487: 148, 1488: 148, 1489: 148, 1490: 149, 1491: 149, 1492: 181, 1493: 181, 1494: 149, 1495: 149, 1496: 149, 1497: 181, 1498: 182, 1499: 149, 1500: 150, 1501: 150, 1502: 150, 1503: 150, 1504: 150, 1505: 150, 1506: 150, 1507: 164, 1508: 150, 1509: 150, 1510: 151, 1511: 182, 1512: 151, 1513: 151, 1514: 151, 1515: 151, 1516: 151, 1517: 151, 1518: 151, 1519: 151, 1520: 152, 1521: 152, 1522: 152, 1523: 164, 1524: 152, 1525: 152, 1526: 152, 1527: 164, 1528: 152, 1529: 152, 1530: 153, 1531: 153, 1532: 153, 1533: 153, 1534: 153, 1535: 182, 1536: 164, 1537: 153, 1538: 153, 1539: 182, 1540: 154, 1541: 154, 1542: 154, 1543: 154, 1544: 154, 1545: 154, 1546: 154, 1547: 154, 1548: 154, 1549: 182, 1550: 155, 1551: 155, 1552: 155, 1553: 155, 1554: 155, 1555: 182, 1556: 164, 1557: 151, 1558: 155, 1559: 155, 1560: 156, 1561: 156, 1562: 164, 1563: 182, 1564: 156, 1565: 156, 1566: 156, 1567: 156, 1568: 156, 1569: 156, 1570: 157, 1571: 157, 1572: 157, 1573: 157, 1574: 157, 1575: 157, 1576: 157, 1577: 157, 1578: 157, 1579: 157, 1580: 164, 1581: 158, 1582: 158, 1583: 158, 1584: 158, 1585: 158, 1586: 154, 1587: 158, 1588: 158, 1589: 158, 1590: 159, 1591: 159, 1592: 159, 1593: 159, 1594: 159, 1595: 164, 1596: 182, 1597: 159, 1598: 154, 1599: 159, 1600: 160, 1601: 160, 1602: 165, 1603: 160, 1604: 160, 1605: 182, 1606: 160, 1607: 160, 1608: 160, 1609: 160, 1610: 161, 1611: 161, 1612: 161, 1613: 161, 1614: 161, 1615: 161, 1616: 161, 1617: 161, 1618: 161, 1619: 161, 1620: 162, 1621: 162, 1622: 182, 1623: 183, 1624: 162, 1625: 162, 1626: 162, 1627: 162, 1628: 162, 1629: 162, 1630: 163, 1631: 165, 1632: 163, 1633: 163, 1634: 183, 1635: 163, 1636: 163, 1637: 163, 1638: 163, 1639: 163, 1640: 164, 1641: 164, 1642: 183, 1643: 164, 1644: 164, 1645: 164, 1646: 165, 1647: 164, 1648: 164, 1649: 164, 1650: 165, 1651: 165, 1652: 183, 1653: 165, 1654: 165, 1655: 165, 1656: 165, 1657: 165, 1658: 165, 1659: 165, 1660: 166, 1661: 166, 1662: 166, 1663: 183, 1664: 166, 1665: 183, 1666: 166, 1667: 166, 1668: 166, 1669: 166, 1670: 183, 1671: 183, 1672: 167, 1673: 167, 1674: 167, 1675: 167, 1676: 183, 1677: 167, 1678: 167, 1679: 167, 1680: 151, 1681: 168, 1682: 168, 1683: 168, 1684: 168, 1685: 168, 1686: 183, 1687: 168, 1688: 168, 1689: 168, 1690: 169, 1691: 169, 1692: 169, 1693: 169, 1694: 169, 1695: 165, 1696: 169, 1697: 169, 1698: 169, 1699: 169, 1700: 170, 1701: 170, 1702: 170, 1703: 170, 1704: 170, 1705: 170, 1706: 170, 1707: 170, 1708: 170, 1709: 170, 1710: 171, 1711: 171, 1712: 171, 1713: 184, 1714: 165, 1715: 171, 1716: 154, 1717: 171, 1718: 171, 1719: 171, 1720: 172, 1721: 172, 1722: 172, 1723: 172, 1724: 172, 1725: 172, 1726: 172, 1727: 184, 1728: 172, 1729: 184, 1730: 173, 1731: 173, 1732: 173, 1733: 173, 1734: 173, 1735: 173, 1736: 173, 1737: 184, 1738: 184, 1739: 173, 1740: 174, 1741: 174, 1742: 174, 1743: 174, 1744: 174, 1745: 174, 1746: 174, 1747: 174, 1748: 174, 1749: 184, 1750: 175, 1751: 175, 1752: 175, 1753: 175, 1754: 165, 1755: 175, 1756: 175, 1757: 175, 1758: 175, 1759: 175, 1760: 184, 1761: 176, 1762: 176, 1763: 176, 1764: 184, 1765: 154, 1766: 176, 1767: 184, 1768: 176, 1769: 176, 1770: 177, 1771: 177, 1772: 151, 1773: 177, 1774: 177, 1775: 154, 1776: 177, 1777: 177, 1778: 177, 1779: 177, 1780: 184, 1781: 178, 1782: 178, 1783: 178, 1784: 178, 1785: 185, 1786: 178, 1787: 178, 1788: 178, 1789: 178, 1790: 155, 1791: 179, 1792: 179, 1793: 179, 1794: 179, 1795: 179, 1796: 179, 1797: 179, 1798: 185, 1799: 179, 1800: 180, 1801: 180, 1802: 180, 1803: 180, 1804: 180, 1805: 180, 1806: 180, 1807: 180, 1808: 180, 1809: 180, 1810: 181, 1811: 181, 1812: 181, 1813: 181, 1814: 181, 1815: 181, 1816: 165, 1817: 181, 1818: 181, 1819: 181, 1820: 182, 1821: 182, 1822: 182, 1823: 165, 1824: 182, 1825: 182, 1826: 182, 1827: 151, 1828: 182, 1829: 182, 1830: 183, 1831: 183, 1832: 183, 1833: 155, 1834: 165, 1835: 183, 1836: 155, 1837: 185, 1838: 183, 1839: 183, 1840: 165, 1841: 184, 1842: 184, 1843: 185, 1844: 184, 1845: 184, 1846: 184, 1847: 184, 1848: 184, 1849: 184, 1850: 185, 1851: 185, 1852: 166, 1853: 185, 1854: 185, 1855: 185}\n",
      "tensor_page_mapping\n",
      "\n",
      "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 1: [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], 2: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184], 3: [65, 162, 5, 75, 141, 174, 178, 147, 54, 155]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "block_page_list = L[0].p_i_j\n",
    "block_page_mapping = dict()\n",
    "for i in range(len(block_page_list)):\n",
    "    block_page_index = block_page_list[i].index(1)\n",
    "    block_page_mapping[i] = block_page_index\n",
    "print(\"block_page_mapping\\n\")\n",
    "print(block_page_mapping)\n",
    "\n",
    "tensor_page_mapping = dict()\n",
    "for t in range(num_tensors):\n",
    "    one_tensor = list_of_tensors[t]\n",
    "    tensor_len = len(one_tensor)\n",
    "    one_tensor_set = set()\n",
    "    for i in range(tensor_len):\n",
    "        page_id = block_page_mapping.get(one_tensor[i])\n",
    "        one_tensor_set.add(page_id)\n",
    "    one_tensor_list = list(one_tensor_set)\n",
    "    tensor_page_mapping[t] = one_tensor_list\n",
    "print(\"tensor_page_mapping\\n\")\n",
    "print(tensor_page_mapping)\n",
    "\n",
    "output = dict()\n",
    "output['block_page_mapping'] = block_page_mapping\n",
    "output['tensor_page_mapping'] = tensor_page_mapping\n",
    "np.save('output.npy',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fa2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
