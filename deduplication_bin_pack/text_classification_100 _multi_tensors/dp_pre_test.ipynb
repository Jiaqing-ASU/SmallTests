{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3348c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "length of this tensor 509\n",
      "the number of total blocks 700\n",
      "the length of new tensor list 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "output = np.load('tensor_list.npy', allow_pickle=True).item()\n",
    "\n",
    "list_tensors = [{}, {}, {}, {}, {}]\n",
    "list_tensors_10 = [{}, {}, {}, {} ,{}, {}, {}, {}, {}, {}]\n",
    "\n",
    "for num in range(5):\n",
    "    a0=set(output['list_of_tensors'][0+num*5])\n",
    "    a1=set(output['list_of_tensors'][1+num*5])\n",
    "    a2=set(output['list_of_tensors'][2+num*5])\n",
    "    a3=set(output['list_of_tensors'][3+num*5])\n",
    "    a4=set(output['list_of_tensors'][4+num*5])\n",
    "    list_tensors[num]=a0.union(a1, a2, a3, a4)\n",
    "\n",
    "list_tensors_l = list(list_tensors)\n",
    "#list_tensors_10_l = list()\n",
    "list_tensors_10_l = list(list_tensors_10)\n",
    "\n",
    "block_id = 677\n",
    "for new_num in range(5):\n",
    "    list_tensors_10_l[new_num] = list_tensors_l[new_num]\n",
    "    this_list = list(list_tensors_l[new_num])\n",
    "    print('length of this tensor', len(this_list))\n",
    "    new_list = list()\n",
    "    #print(new_list)\n",
    "    for i in range(len(this_list)):\n",
    "        flag = random.randint(1,100)\n",
    "        #print(flag)\n",
    "        if(flag <= 98):\n",
    "            new_list.append(this_list[i])\n",
    "            #print(new_list)\n",
    "        elif(flag <= 99):\n",
    "            which_block = random.randint(0,399)\n",
    "            new_list.append(which_block)\n",
    "        else:\n",
    "            block_id = block_id + 1\n",
    "            new_list.append(block_id)\n",
    "    #print(new_list)\n",
    "    print('length of this tensor', len(new_list))\n",
    "    list_tensors_10_l[new_num + 5] = new_list\n",
    "    #print(list_tensors_10_l[new_num + 5])\n",
    "\n",
    "print('the number of total blocks', block_id)\n",
    "#list_tensors_10_l = list(list_tensors_10)\n",
    "print('the length of new tensor list', len(list_tensors_10_l))\n",
    "#print(list_tensors_10_l)\n",
    "#print(list_tensors_10_l[9])\n",
    "new_output = dict()\n",
    "new_output['list_of_tensors'] = list_tensors_10_l\n",
    "np.save('new_tensor_list_10.npy', new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e185fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
      "377\n",
      "(0, 1, 2, 3, 4, 6, 7, 8, 9)\n",
      "5\n",
      "(0, 1, 2, 3, 4, 5, 7, 8, 9)\n",
      "7\n",
      "(0, 1, 2, 3, 4, 5, 6, 8, 9)\n",
      "3\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 9)\n",
      "6\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8)\n",
      "8\n",
      "(0, 2, 3, 4, 5, 7, 8, 9)\n",
      "1\n",
      "(0, 1, 2, 4, 5, 6, 7, 9)\n",
      "43\n",
      "(0, 1, 2, 3, 4, 6, 7, 9)\n",
      "1\n",
      "(0, 1, 2, 3, 4, 5, 7, 8)\n",
      "1\n",
      "(0, 1, 2, 4, 6, 7, 9)\n",
      "2\n",
      "(0, 1, 2, 4, 5, 7, 9)\n",
      "2\n",
      "(0, 1, 2, 4, 5, 6, 9)\n",
      "1\n",
      "(0, 1, 2, 4, 5, 6, 7)\n",
      "1\n",
      "(1, 2, 4, 6, 7, 9)\n",
      "1\n",
      "(0, 2, 4, 5, 7, 9)\n",
      "33\n",
      "(1, 2, 4, 7, 9)\n",
      "1\n",
      "(0, 2, 4, 5, 7)\n",
      "3\n",
      "(9, 2, 4, 7)\n",
      "9\n",
      "(9, 4)\n",
      "4\n",
      "(8, 3)\n",
      "99\n",
      "(2, 7)\n",
      "4\n",
      "(1, 6)\n",
      "49\n",
      "(0, 5)\n",
      "15\n",
      "(1,)\n",
      "1\n",
      "(3,)\n",
      "1\n",
      "(5,)\n",
      "4\n",
      "(6,)\n",
      "7\n",
      "(7,)\n",
      "2\n",
      "(8,)\n",
      "5\n",
      "(9,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import timeit\n",
    "from sympy.utilities.iterables import multiset_combinations\n",
    "\n",
    "def get_key(dict, value):\n",
    "    return [k for k, v in dict.items() if v != value]\n",
    "\n",
    "input_list = np.load('new_tensor_list_10.npy', allow_pickle=True).item()\n",
    "#list_tensors_10_l = list(input_list['list_of_tensors'])\n",
    "list_tensors_10_l = input_list['list_of_tensors']\n",
    "\n",
    "tensor_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "tensors_union_dic = dict()\n",
    "tensors_union_dic_len = dict()\n",
    "thistuple = (0,1,2,3,4,5,6,7,8,9)\n",
    "whole_share = (0,1,2,3,4,5,6,7,8,9)\n",
    "thisset = list_tensors_10_l[0].intersection(list_tensors_10_l[1])\n",
    "for i in range(2, 10):\n",
    "    thisset = thisset.intersection(list_tensors_10_l[i])\n",
    "tensors_union_dic[thistuple] = thisset\n",
    "tensors_union_dic_len[thistuple] = len(thisset)\n",
    "#print(tensors_union_dic)\n",
    "\n",
    "whole_share_set = tensors_union_dic[whole_share]\n",
    "#print(whole_share_set)\n",
    "\n",
    "this_com = list(multiset_combinations(tensor_list,1))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = list_tensors_10_l[curr_list[0]].intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(thisset)\n",
    "    #print(tensors_union_dic.get(whole_share))\n",
    "    #print(whole_share_set)\n",
    "    thisset = thisset - set(tensors_union_dic[whole_share])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    #print(thisset)\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "#print(tensors_union_dic_len)\n",
    "\n",
    "#print(tensors_union_dic[whole_share])\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,2))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = list_tensors_10_l[curr_list[0]].intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,3))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = list_tensors_10_l[curr_list[0]].intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,4))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = list_tensors_10_l[curr_list[0]].intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,5))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = set(list_tensors_10_l[curr_list[0]]).intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,6))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = set(list_tensors_10_l[curr_list[0]]).intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,7))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = set(list_tensors_10_l[curr_list[0]]).intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,8))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    curr_com_without = this_com[i]\n",
    "    curr_list = list(set(tensor_list)-set(curr_com_without))\n",
    "    thistuple = tuple(curr_list)\n",
    "    thisset = set(list_tensors_10_l[curr_list[0]]).intersection(list_tensors_10_l[curr_list[1]])\n",
    "    for j in range(2, len(curr_list)):\n",
    "        thisset = thisset.intersection(list_tensors_10_l[curr_list[j]])\n",
    "    #print(tensors_union_dic[whole_share])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "\n",
    "this_com.clear()\n",
    "this_com = list(multiset_combinations(tensor_list,1))\n",
    "#print(this_com)\n",
    "for i in range(len(this_com)):\n",
    "    #thisset.clear()\n",
    "    temp = list(thistuple)\n",
    "    temp.clear()\n",
    "    thistuple = tuple(temp)\n",
    "    #curr_com_without = this_com[i]\n",
    "    curr_list = this_com[i]\n",
    "    thistuple = tuple(curr_list)\n",
    "    #list_index = curr_list\n",
    "    thisset = set(list_tensors_10_l[curr_list[0]])\n",
    "    thisset = thisset - tensors_union_dic[(0,1,2,3,4,5,6,7,8,9)]\n",
    "    for key in tensors_union_dic:\n",
    "        this_key = list(key)\n",
    "        tag = True\n",
    "        for k in range(len(curr_list)):\n",
    "            if curr_list[k] not in this_key:\n",
    "                tag = False\n",
    "        if(tag):\n",
    "            thisset = thisset - tensors_union_dic[key]\n",
    "    tensors_union_dic[thistuple] = thisset\n",
    "    tensors_union_dic_len[thistuple] = len(thisset)\n",
    "\n",
    "\n",
    "#print(tensors_union_dic_len)\n",
    "key_list = get_key(tensors_union_dic_len, 0)\n",
    "#print(key_list)\n",
    "for i in range(len(key_list)):\n",
    "    print(key_list[i])\n",
    "    print(tensors_union_dic_len[key_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc61b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import timeit\n",
    "\n",
    "output = np.load('tensor_list.npy', allow_pickle=True).item()\n",
    "#output.keys()\n",
    "#print(output['list_of_tensors'])\n",
    "\n",
    "list = [{}, {}, {}, {}, {}]\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for num in range(5):\n",
    "    a0=set(output['list_of_tensors'][0+num*5])\n",
    "    a1=set(output['list_of_tensors'][1+num*5])\n",
    "    a2=set(output['list_of_tensors'][2+num*5])\n",
    "    a3=set(output['list_of_tensors'][3+num*5])\n",
    "    a4=set(output['list_of_tensors'][4+num*5])\n",
    "    list[num]=a0.union(a1, a2, a3, a4)\n",
    "    #print(list[num])\n",
    "\n",
    "#index = [0, 1, 2, 3, 4]\n",
    "#for L in range(0, len(index)+1):\n",
    "#    for subset in itertools.combinations(index, L):\n",
    "#        print(subset)\n",
    "\n",
    "print(\"Shared by all tensors:\")\n",
    "l01234=list[0].intersection(list[1], list[2], list[3], list[4])\n",
    "#print(l01234)\n",
    "print(len(l01234))\n",
    "\n",
    "print(\"Shared by 0, 1, 2, 3:\")\n",
    "l0123=list[0].intersection(list[1], list[2], list[3])-l01234\n",
    "#print(l0123)\n",
    "print(len(l0123))\n",
    "\n",
    "print(\"Shared by 0, 1, 2, 4:\")\n",
    "l0124=list[0].intersection(list[1], list[2], list[4])-l01234\n",
    "#print(l0124)\n",
    "print(len(l0124))\n",
    "\n",
    "print(\"Shared by 0, 1, 3, 4:\")\n",
    "l0134=list[0].intersection(list[1], list[3], list[4])-l01234\n",
    "#print(l0134)\n",
    "print(len(l0134))\n",
    "\n",
    "print(\"Shared by 0, 2, 3, 4:\")\n",
    "l0234=list[0].intersection(list[2], list[3], list[4])-l01234\n",
    "#print(l0234)\n",
    "print(len(l0234))\n",
    "\n",
    "print(\"Shared by 1, 2, 3, 4:\")\n",
    "l1234=list[1].intersection(list[2], list[3], list[4])-l01234\n",
    "#print(l1234)\n",
    "print(len(l1234))\n",
    "\n",
    "print(\"Shared by 0, 1, 2:\")\n",
    "l012=list[0].intersection(list[1], list[2])-l0123-l0124-l01234\n",
    "#print(l012)\n",
    "print(len(l012))\n",
    "\n",
    "print(\"Shared by 0, 1, 3:\")\n",
    "l013=list[0].intersection(list[1], list[3])-l0123-l0134-l01234\n",
    "#print(l013)\n",
    "print(len(l013))\n",
    "\n",
    "print(\"Shared by 0, 1, 4:\")\n",
    "l014=list[0].intersection(list[1], list[4])-l0124-l0134-l01234\n",
    "#print(l014)\n",
    "print(len(l014))\n",
    "\n",
    "print(\"Shared by 0, 2, 3:\")\n",
    "l023=list[0].intersection(list[2], list[3])-l0123-l0234-l01234\n",
    "#print(l023)\n",
    "print(len(l023))\n",
    "\n",
    "print(\"Shared by 0, 2, 4:\")\n",
    "l024=list[0].intersection(list[2], list[4])-l0124-l0234-l01234\n",
    "#print(l024)\n",
    "print(len(l024))\n",
    "\n",
    "print(\"Shared by 0, 3, 4:\")\n",
    "l034=list[0].intersection(list[3], list[4])-l0134-l0234-l01234\n",
    "#print(l034)\n",
    "print(len(l034))\n",
    "\n",
    "print(\"Shared by 1, 2, 3:\")\n",
    "l123=list[1].intersection(list[2], list[3])-l0123-l1234-l01234\n",
    "#print(l123)\n",
    "print((l123))\n",
    "\n",
    "print(\"Shared by 1, 2, 4:\")\n",
    "l124=list[1].intersection(list[2], list[4])-l0124-l1234-l01234\n",
    "#print(l124)\n",
    "print(len(l124))\n",
    "\n",
    "print(\"Shared by 1, 3, 4:\")\n",
    "l134=list[1].intersection(list[3], list[4])-l0134-l1234-l01234\n",
    "#print(l134)\n",
    "print(len(l134))\n",
    "\n",
    "print(\"Shared by 2, 3, 4:\")\n",
    "l234=list[2].intersection(list[3], list[4])-l0234-l1234-l01234\n",
    "#print(l234)\n",
    "print(len(l234))\n",
    "\n",
    "print(\"Shared by 0, 1:\")\n",
    "l01=list[0].intersection(list[1])-l012-l013-l014-l0123-l0124-l0134-l01234\n",
    "#print(l01)\n",
    "print(len(l01))\n",
    "\n",
    "print(\"Shared by 0, 2:\")\n",
    "l02=list[0].intersection(list[2])-l012-l023-l024-l0123-l0124-l0234-l01234\n",
    "#print(l02)\n",
    "print(len(l02))\n",
    "\n",
    "print(\"Shared by 0, 3:\")\n",
    "l03=list[0].intersection(list[3])-l013-l023-l034-l0123-l0234-l0234-l01234\n",
    "#print(l03)\n",
    "print(len(l03))\n",
    "\n",
    "print(\"Shared by 0, 4:\")\n",
    "l04=list[0].intersection(list[4])-l014-l024-l034-l0124-l0134-l0234-l01234\n",
    "#print(l04)\n",
    "print(len(l04))\n",
    "\n",
    "print(\"Shared by 1, 2:\")\n",
    "l12=list[1].intersection(list[2])-l012-l123-l124-l0123-l0124-l1234-l01234\n",
    "#print(l12)\n",
    "print(len(l12))\n",
    "\n",
    "print(\"Shared by 1, 3:\")\n",
    "l13=list[1].intersection(list[3])-l013-l034-l134-l0123-l0134-l1234-l01234\n",
    "#print(l13)\n",
    "print(len(l13))\n",
    "\n",
    "print(\"Shared by 1, 4:\")\n",
    "l14=list[1].intersection(list[4])-l014-l124-l134-l0124-l0134-l1234-l01234\n",
    "#print(l14)\n",
    "print(len(l14))\n",
    "\n",
    "print(\"Shared by 2, 3:\")\n",
    "l23=list[2].intersection(list[3])-l023-l123-l234-l0123-l0234-l1234-l01234\n",
    "#print(l23)\n",
    "print(len(l23))\n",
    "\n",
    "print(\"Shared by 2, 4:\")\n",
    "l24=list[2].intersection(list[4])-l024-l124-l234-l0124-l0234-l1234-l01234\n",
    "#print(l24)\n",
    "print(len(l24))\n",
    "\n",
    "print(\"Shared by 3, 4:\")\n",
    "l34=list[3].intersection(list[4])-l034-l134-l234-l0134-l0234-l1234-l01234\n",
    "#print(l34)\n",
    "print(len(l34))\n",
    "\n",
    "print(\"Private to 0:\")\n",
    "l0=list[0]-l01-l02-l03-l04-l012-l013-l014-l023-l024-l034-l0123-l0124-l0134-l0234-l01234\n",
    "#print(l0)\n",
    "print(len(l0))\n",
    "\n",
    "print(\"Private to 1:\")\n",
    "l1=list[1]-l01-l12-l13-l14-l012-l013-l014-l123-l124-l134-l0123-l0124-l0134-l1234-l01234\n",
    "#print(l1)\n",
    "print(len(l1))\n",
    "\n",
    "print(\"Private to 2:\")\n",
    "l2=list[2]-l02-l12-l23-l24-l012-l023-l024-l123-l124-l234-l0123-l0124-l0234-l1234-l01234\n",
    "#print(l2)\n",
    "print(len(l2))\n",
    "\n",
    "print(\"Private to 3:\")\n",
    "l3=list[3]-l03-l13-l23-l34-l013-l023-l034-l123-l134-l234-l0123-l0134-l0234-l1234-l01234\n",
    "#print(l3)\n",
    "print(len(l3))\n",
    "\n",
    "print(\"Private to 4:\")\n",
    "l4=list[4]-l04-l14-l24-l34-l014-l024-l034-l124-l134-l234-l0124-l0134-l0234-l1234-l01234\n",
    "#print(l4)\n",
    "print(len(l4))\n",
    "stop = timeit.default_timer()\n",
    "t1 = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = ['A','B','C','C','C','C']\n",
    "list_combinations_of_n = list(multiset_combinations(l0, min(5,len(l0))))\n",
    "print(list_combinations_of_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy.utilities.iterables import multiset_combinations\n",
    "\n",
    "#ll0=[491,501,487,488,493,494,665,666,667,668,669,670,671]\n",
    "#ll1=[491,410,490,561,562]\n",
    "#ll2=[491,501,487,488,493,494,410,490,415,512,509,510,511]\n",
    "#ll3=[501,659,660,661,662]\n",
    "#ll4=[491,501,487,488,493,494,410,490,415,505,506,507,508]\n",
    "\n",
    "#ll0=[('A',0),('B',0),('C',1),('C',2),('C',3),('C',4)]\n",
    "#ll1=[('A',0),('D',0),('D',1)]\n",
    "#ll2=[('A',0),('B',0),('C',1),('C',2),('C',3),('C',4),('D',0),('D',1),('E',0)]\n",
    "#ll3=[('B',0)]\n",
    "#ll4=[]\n",
    "\n",
    "ll0 = ['A','B','C','C','C','C']\n",
    "ll1 = ['A','D','D']\n",
    "ll2 = ['A','B','C','C','C','C','D','D','E']\n",
    "ll3 = ['B']\n",
    "\n",
    "\n",
    "#ll0=[491,501,487,488,493,494,665,666,667,668,669,670,671]\n",
    "#ll1=[491,410,490,561,562]\n",
    "#ll2=[491,501,487,488,493,494,410,490,415,512,509,510,511]\n",
    "#ll3=[501,659,660,661,662]\n",
    "#ll4=[491,501,487,488,493,494,410,490,415,505,506,507,508]\n",
    "blocks_in_page = 8\n",
    "\n",
    "list_of_tensors = [ll0,ll1,ll2,ll3]\n",
    "\n",
    "list_of_real_len = [13,5,13,5,13]\n",
    "\n",
    "min_combination = blocks_in_page - 1\n",
    "for i in range(len(list_of_real_len)):\n",
    "    if(list_of_real_len[i] < min_combination):\n",
    "        min_combination = list_of_real_len[i]%blocks_in_page\n",
    "\n",
    "print(list_of_tensors)\n",
    "print(min_combination)\n",
    "\n",
    "\n",
    "#while(max(list_of_real_len)>blocks_in_page):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.arraysetops import unique\n",
    "from bin_pack import *\n",
    "import uuid\n",
    "import hashlib\n",
    "import timeit\n",
    "\n",
    "ll0 = ['A','B','C','C','C','C']\n",
    "ll1 = ['A','D','D']\n",
    "ll2 = ['A','B','C','C','C','C','D','D','E']\n",
    "ll3 = ['B']\n",
    "ll4 = ['A','B','C','C','C','C','D','D','E']\n",
    "\n",
    "lll0=[('A',0),('B',0),('C',0),('C',1),('C',2),('C',3),('F',0),('F',1),('F',2),('F',3),('F',4),('F',5),('F',6)]\n",
    "lll1=[('A',0),('D',0),('D',1),('G',0),('G',1)]\n",
    "lll2=[('A',0),('B',0),('C',0),('C',1),('C',2),('C',3),('D',0),('D',1),('E',0),('H',0),('H',1),('H',2),('H',3)]\n",
    "lll3=[('B',0),('I',0),('I',1),('I',2),('I',3)]\n",
    "lll4=[('A',0),('B',0),('C',0),('C',1),('C',2),('C',3),('D',0),('D',1),('E',0),('J',0),('J',1),('J',2),('J',3)]\n",
    "flag = True\n",
    "\n",
    "list_of_tensors_1 = [ll0,ll1,ll2,ll3,ll4]\n",
    "list_of_org_tensors_1 = [lll0,lll1,lll2,lll3,lll4]\n",
    "list_of_real_len_1 = [13,5,13,5,13]\n",
    "\n",
    "#list_of_tensors_2 = [ll2,ll0,ll1,ll3,ll4]\n",
    "#list_of_org_tensors_2 = [lll2,lll0,lll1,lll3,lll4]\n",
    "#list_of_real_len_2 = [13,13,5,13,5]\n",
    "\n",
    "#list_of_tensors_3 = [ll4,ll0,ll1,ll2,ll3]\n",
    "#list_of_org_tensors_3 = [lll4,lll0,lll1,lll2,lll3]\n",
    "#list_of_real_len_3 = [13,13,5,13,5]\n",
    "\n",
    "blocks_in_page = 8 # page can have 8 blocks\n",
    "P = set()\n",
    "start = timeit.default_timer()\n",
    "P = bin_pack_dp(list_of_tensors_1, list_of_org_tensors_1, blocks_in_page, list_of_real_len_1,flag)\n",
    "#print('finish one')\n",
    "#P.union(bin_pack_dp(list_of_tensors_2, list_of_org_tensors_2, blocks_in_page, list_of_real_len_2,flag))\n",
    "#print('finish two')\n",
    "#P.union(bin_pack_dp(list_of_tensors_3, list_of_org_tensors_3, blocks_in_page, list_of_real_len_3,flag))\n",
    "stop = timeit.default_timer()\n",
    "t2 = stop - start\n",
    "\n",
    "#L = list(P)\n",
    "#for i in range(len(L)):\n",
    "#    print(L[i].numBins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = list(P)\n",
    "for i in range(len(L)):\n",
    "    print(L[i].numBins)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e16e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 0\n",
    "l = 8\n",
    "start = timeit.default_timer()\n",
    "\n",
    "I = [l01234,l0124,l0234,l024,l124,l24,l0,l1,l2,l3,l4]\n",
    "p_i_j = BinPackingScheme(I, l)\n",
    "\n",
    "for i in range(len(I)):\n",
    "    j = i + 1\n",
    "    s = math.ceil(i / l) + 1\n",
    "    p_i_j.mark(j, s)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "t3 = stop - start\n",
    "\n",
    "print('Time: ', t1+t2+t3)\n",
    "print('Time: ', t1+t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = dict()\n",
    "tensor_page_mapping = dict()\n",
    "one_tensor_set = set()\n",
    "for i in range(0,2):\n",
    "    one_tensor_set.add(i)\n",
    "for i in range(6,67):\n",
    "    one_tensor_set.add(i)\n",
    "one_tensor_set.add(68)\n",
    "one_tensor_list = list(one_tensor_set)\n",
    "tensor_page_mapping[0] = one_tensor_list\n",
    "\n",
    "one_tensor_set2 = set()\n",
    "one_tensor_set2.add(2)\n",
    "for i in range(6,63):\n",
    "    one_tensor_set2.add(i)\n",
    "for i in range(69,75):\n",
    "    one_tensor_set2.add(i)\n",
    "one_tensor_list2 = list(one_tensor_set2)\n",
    "tensor_page_mapping[1] = one_tensor_list2\n",
    "\n",
    "one_tensor_set3 = set()\n",
    "one_tensor_set3.add(0)\n",
    "one_tensor_set3.add(3)\n",
    "for i in range(6,68):\n",
    "    one_tensor_set3.add(i)\n",
    "one_tensor_list3 = list(one_tensor_set3)\n",
    "tensor_page_mapping[2] = one_tensor_list3\n",
    "\n",
    "one_tensor_set4 = set()\n",
    "one_tensor_set4.add(4)\n",
    "for i in range(6,57):\n",
    "    one_tensor_set4.add(i)\n",
    "for i in range(75,87):\n",
    "    one_tensor_set4.add(i)\n",
    "one_tensor_list4 = list(one_tensor_set4)\n",
    "tensor_page_mapping[3] = one_tensor_list4\n",
    "\n",
    "one_tensor_set5 = set()\n",
    "one_tensor_set5.add(0)\n",
    "one_tensor_set5.add(5)\n",
    "for i in range(6,68):\n",
    "    one_tensor_set5.add(i)\n",
    "one_tensor_list5 = list(one_tensor_set5)\n",
    "tensor_page_mapping[4] = one_tensor_list5\n",
    "\n",
    "print(\"tensor_page_mapping:\")\n",
    "print(tensor_page_mapping)\n",
    "\n",
    "output['tensor_page_mapping'] = tensor_page_mapping\n",
    "np.save('dp_page_pack_output.npy',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42a2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
